Model :

graph torch-jit-export (
  %input[FLOAT, batch_sizex3x224x224]
) initializers (
  %bn1.bias[FLOAT, 64]
  %bn1.running_mean[FLOAT, 64]
  %bn1.running_var[FLOAT, 64]
  %bn1.weight[FLOAT, 64]
  %conv1.weight[FLOAT, 64x3x7x7]
  %fc.bias[FLOAT, 1000]
  %fc.weight[FLOAT, 1000x2048]
  %layer1.0.bn1.bias[FLOAT, 64]
  %layer1.0.bn1.running_mean[FLOAT, 64]
  %layer1.0.bn1.running_var[FLOAT, 64]
  %layer1.0.bn1.weight[FLOAT, 64]
  %layer1.0.bn2.bias[FLOAT, 64]
  %layer1.0.bn2.running_mean[FLOAT, 64]
  %layer1.0.bn2.running_var[FLOAT, 64]
  %layer1.0.bn2.weight[FLOAT, 64]
  %layer1.0.bn3.bias[FLOAT, 256]
  %layer1.0.bn3.running_mean[FLOAT, 256]
  %layer1.0.bn3.running_var[FLOAT, 256]
  %layer1.0.bn3.weight[FLOAT, 256]
  %layer1.0.conv1.weight[FLOAT, 64x64x1x1]
  %layer1.0.conv2.weight[FLOAT, 64x64x3x3]
  %layer1.0.conv3.weight[FLOAT, 256x64x1x1]
  %layer1.0.downsample.0.weight[FLOAT, 256x64x1x1]
  %layer1.0.downsample.1.bias[FLOAT, 256]
  %layer1.0.downsample.1.running_mean[FLOAT, 256]
  %layer1.0.downsample.1.running_var[FLOAT, 256]
  %layer1.0.downsample.1.weight[FLOAT, 256]
  %layer1.1.bn1.bias[FLOAT, 64]
  %layer1.1.bn1.running_mean[FLOAT, 64]
  %layer1.1.bn1.running_var[FLOAT, 64]
  %layer1.1.bn1.weight[FLOAT, 64]
  %layer1.1.bn2.bias[FLOAT, 64]
  %layer1.1.bn2.running_mean[FLOAT, 64]
  %layer1.1.bn2.running_var[FLOAT, 64]
  %layer1.1.bn2.weight[FLOAT, 64]
  %layer1.1.bn3.bias[FLOAT, 256]
  %layer1.1.bn3.running_mean[FLOAT, 256]
  %layer1.1.bn3.running_var[FLOAT, 256]
  %layer1.1.bn3.weight[FLOAT, 256]
  %layer1.1.conv1.weight[FLOAT, 64x256x1x1]
  %layer1.1.conv2.weight[FLOAT, 64x64x3x3]
  %layer1.1.conv3.weight[FLOAT, 256x64x1x1]
  %layer1.2.bn1.bias[FLOAT, 64]
  %layer1.2.bn1.running_mean[FLOAT, 64]
  %layer1.2.bn1.running_var[FLOAT, 64]
  %layer1.2.bn1.weight[FLOAT, 64]
  %layer1.2.bn2.bias[FLOAT, 64]
  %layer1.2.bn2.running_mean[FLOAT, 64]
  %layer1.2.bn2.running_var[FLOAT, 64]
  %layer1.2.bn2.weight[FLOAT, 64]
  %layer1.2.bn3.bias[FLOAT, 256]
  %layer1.2.bn3.running_mean[FLOAT, 256]
  %layer1.2.bn3.running_var[FLOAT, 256]
  %layer1.2.bn3.weight[FLOAT, 256]
  %layer1.2.conv1.weight[FLOAT, 64x256x1x1]
  %layer1.2.conv2.weight[FLOAT, 64x64x3x3]
  %layer1.2.conv3.weight[FLOAT, 256x64x1x1]
  %layer2.0.bn1.bias[FLOAT, 128]
  %layer2.0.bn1.running_mean[FLOAT, 128]
  %layer2.0.bn1.running_var[FLOAT, 128]
  %layer2.0.bn1.weight[FLOAT, 128]
  %layer2.0.bn2.bias[FLOAT, 128]
  %layer2.0.bn2.running_mean[FLOAT, 128]
  %layer2.0.bn2.running_var[FLOAT, 128]
  %layer2.0.bn2.weight[FLOAT, 128]
  %layer2.0.bn3.bias[FLOAT, 512]
  %layer2.0.bn3.running_mean[FLOAT, 512]
  %layer2.0.bn3.running_var[FLOAT, 512]
  %layer2.0.bn3.weight[FLOAT, 512]
  %layer2.0.conv1.weight[FLOAT, 128x256x1x1]
  %layer2.0.conv2.weight[FLOAT, 128x128x3x3]
  %layer2.0.conv3.weight[FLOAT, 512x128x1x1]
  %layer2.0.downsample.0.weight[FLOAT, 512x256x1x1]
  %layer2.0.downsample.1.bias[FLOAT, 512]
  %layer2.0.downsample.1.running_mean[FLOAT, 512]
  %layer2.0.downsample.1.running_var[FLOAT, 512]
  %layer2.0.downsample.1.weight[FLOAT, 512]
  %layer2.1.bn1.bias[FLOAT, 128]
  %layer2.1.bn1.running_mean[FLOAT, 128]
  %layer2.1.bn1.running_var[FLOAT, 128]
  %layer2.1.bn1.weight[FLOAT, 128]
  %layer2.1.bn2.bias[FLOAT, 128]
  %layer2.1.bn2.running_mean[FLOAT, 128]
  %layer2.1.bn2.running_var[FLOAT, 128]
  %layer2.1.bn2.weight[FLOAT, 128]
  %layer2.1.bn3.bias[FLOAT, 512]
  %layer2.1.bn3.running_mean[FLOAT, 512]
  %layer2.1.bn3.running_var[FLOAT, 512]
  %layer2.1.bn3.weight[FLOAT, 512]
  %layer2.1.conv1.weight[FLOAT, 128x512x1x1]
  %layer2.1.conv2.weight[FLOAT, 128x128x3x3]
  %layer2.1.conv3.weight[FLOAT, 512x128x1x1]
  %layer2.2.bn1.bias[FLOAT, 128]
  %layer2.2.bn1.running_mean[FLOAT, 128]
  %layer2.2.bn1.running_var[FLOAT, 128]
  %layer2.2.bn1.weight[FLOAT, 128]
  %layer2.2.bn2.bias[FLOAT, 128]
  %layer2.2.bn2.running_mean[FLOAT, 128]
  %layer2.2.bn2.running_var[FLOAT, 128]
  %layer2.2.bn2.weight[FLOAT, 128]
  %layer2.2.bn3.bias[FLOAT, 512]
  %layer2.2.bn3.running_mean[FLOAT, 512]
  %layer2.2.bn3.running_var[FLOAT, 512]
  %layer2.2.bn3.weight[FLOAT, 512]
  %layer2.2.conv1.weight[FLOAT, 128x512x1x1]
  %layer2.2.conv2.weight[FLOAT, 128x128x3x3]
  %layer2.2.conv3.weight[FLOAT, 512x128x1x1]
  %layer2.3.bn1.bias[FLOAT, 128]
  %layer2.3.bn1.running_mean[FLOAT, 128]
  %layer2.3.bn1.running_var[FLOAT, 128]
  %layer2.3.bn1.weight[FLOAT, 128]
  %layer2.3.bn2.bias[FLOAT, 128]
  %layer2.3.bn2.running_mean[FLOAT, 128]
  %layer2.3.bn2.running_var[FLOAT, 128]
  %layer2.3.bn2.weight[FLOAT, 128]
  %layer2.3.bn3.bias[FLOAT, 512]
  %layer2.3.bn3.running_mean[FLOAT, 512]
  %layer2.3.bn3.running_var[FLOAT, 512]
  %layer2.3.bn3.weight[FLOAT, 512]
  %layer2.3.conv1.weight[FLOAT, 128x512x1x1]
  %layer2.3.conv2.weight[FLOAT, 128x128x3x3]
  %layer2.3.conv3.weight[FLOAT, 512x128x1x1]
  %layer3.0.bn1.bias[FLOAT, 256]
  %layer3.0.bn1.running_mean[FLOAT, 256]
  %layer3.0.bn1.running_var[FLOAT, 256]
  %layer3.0.bn1.weight[FLOAT, 256]
  %layer3.0.bn2.bias[FLOAT, 256]
  %layer3.0.bn2.running_mean[FLOAT, 256]
  %layer3.0.bn2.running_var[FLOAT, 256]
  %layer3.0.bn2.weight[FLOAT, 256]
  %layer3.0.bn3.bias[FLOAT, 1024]
  %layer3.0.bn3.running_mean[FLOAT, 1024]
  %layer3.0.bn3.running_var[FLOAT, 1024]
  %layer3.0.bn3.weight[FLOAT, 1024]
  %layer3.0.conv1.weight[FLOAT, 256x512x1x1]
  %layer3.0.conv2.weight[FLOAT, 256x256x3x3]
  %layer3.0.conv3.weight[FLOAT, 1024x256x1x1]
  %layer3.0.downsample.0.weight[FLOAT, 1024x512x1x1]
  %layer3.0.downsample.1.bias[FLOAT, 1024]
  %layer3.0.downsample.1.running_mean[FLOAT, 1024]
  %layer3.0.downsample.1.running_var[FLOAT, 1024]
  %layer3.0.downsample.1.weight[FLOAT, 1024]
  %layer3.1.bn1.bias[FLOAT, 256]
  %layer3.1.bn1.running_mean[FLOAT, 256]
  %layer3.1.bn1.running_var[FLOAT, 256]
  %layer3.1.bn1.weight[FLOAT, 256]
  %layer3.1.bn2.bias[FLOAT, 256]
  %layer3.1.bn2.running_mean[FLOAT, 256]
  %layer3.1.bn2.running_var[FLOAT, 256]
  %layer3.1.bn2.weight[FLOAT, 256]
  %layer3.1.bn3.bias[FLOAT, 1024]
  %layer3.1.bn3.running_mean[FLOAT, 1024]
  %layer3.1.bn3.running_var[FLOAT, 1024]
  %layer3.1.bn3.weight[FLOAT, 1024]
  %layer3.1.conv1.weight[FLOAT, 256x1024x1x1]
  %layer3.1.conv2.weight[FLOAT, 256x256x3x3]
  %layer3.1.conv3.weight[FLOAT, 1024x256x1x1]
  %layer3.2.bn1.bias[FLOAT, 256]
  %layer3.2.bn1.running_mean[FLOAT, 256]
  %layer3.2.bn1.running_var[FLOAT, 256]
  %layer3.2.bn1.weight[FLOAT, 256]
  %layer3.2.bn2.bias[FLOAT, 256]
  %layer3.2.bn2.running_mean[FLOAT, 256]
  %layer3.2.bn2.running_var[FLOAT, 256]
  %layer3.2.bn2.weight[FLOAT, 256]
  %layer3.2.bn3.bias[FLOAT, 1024]
  %layer3.2.bn3.running_mean[FLOAT, 1024]
  %layer3.2.bn3.running_var[FLOAT, 1024]
  %layer3.2.bn3.weight[FLOAT, 1024]
  %layer3.2.conv1.weight[FLOAT, 256x1024x1x1]
  %layer3.2.conv2.weight[FLOAT, 256x256x3x3]
  %layer3.2.conv3.weight[FLOAT, 1024x256x1x1]
  %layer3.3.bn1.bias[FLOAT, 256]
  %layer3.3.bn1.running_mean[FLOAT, 256]
  %layer3.3.bn1.running_var[FLOAT, 256]
  %layer3.3.bn1.weight[FLOAT, 256]
  %layer3.3.bn2.bias[FLOAT, 256]
  %layer3.3.bn2.running_mean[FLOAT, 256]
  %layer3.3.bn2.running_var[FLOAT, 256]
  %layer3.3.bn2.weight[FLOAT, 256]
  %layer3.3.bn3.bias[FLOAT, 1024]
  %layer3.3.bn3.running_mean[FLOAT, 1024]
  %layer3.3.bn3.running_var[FLOAT, 1024]
  %layer3.3.bn3.weight[FLOAT, 1024]
  %layer3.3.conv1.weight[FLOAT, 256x1024x1x1]
  %layer3.3.conv2.weight[FLOAT, 256x256x3x3]
  %layer3.3.conv3.weight[FLOAT, 1024x256x1x1]
  %layer3.4.bn1.bias[FLOAT, 256]
  %layer3.4.bn1.running_mean[FLOAT, 256]
  %layer3.4.bn1.running_var[FLOAT, 256]
  %layer3.4.bn1.weight[FLOAT, 256]
  %layer3.4.bn2.bias[FLOAT, 256]
  %layer3.4.bn2.running_mean[FLOAT, 256]
  %layer3.4.bn2.running_var[FLOAT, 256]
  %layer3.4.bn2.weight[FLOAT, 256]
  %layer3.4.bn3.bias[FLOAT, 1024]
  %layer3.4.bn3.running_mean[FLOAT, 1024]
  %layer3.4.bn3.running_var[FLOAT, 1024]
  %layer3.4.bn3.weight[FLOAT, 1024]
  %layer3.4.conv1.weight[FLOAT, 256x1024x1x1]
  %layer3.4.conv2.weight[FLOAT, 256x256x3x3]
  %layer3.4.conv3.weight[FLOAT, 1024x256x1x1]
  %layer3.5.bn1.bias[FLOAT, 256]
  %layer3.5.bn1.running_mean[FLOAT, 256]
  %layer3.5.bn1.running_var[FLOAT, 256]
  %layer3.5.bn1.weight[FLOAT, 256]
  %layer3.5.bn2.bias[FLOAT, 256]
  %layer3.5.bn2.running_mean[FLOAT, 256]
  %layer3.5.bn2.running_var[FLOAT, 256]
  %layer3.5.bn2.weight[FLOAT, 256]
  %layer3.5.bn3.bias[FLOAT, 1024]
  %layer3.5.bn3.running_mean[FLOAT, 1024]
  %layer3.5.bn3.running_var[FLOAT, 1024]
  %layer3.5.bn3.weight[FLOAT, 1024]
  %layer3.5.conv1.weight[FLOAT, 256x1024x1x1]
  %layer3.5.conv2.weight[FLOAT, 256x256x3x3]
  %layer3.5.conv3.weight[FLOAT, 1024x256x1x1]
  %layer4.0.bn1.bias[FLOAT, 512]
  %layer4.0.bn1.running_mean[FLOAT, 512]
  %layer4.0.bn1.running_var[FLOAT, 512]
  %layer4.0.bn1.weight[FLOAT, 512]
  %layer4.0.bn2.bias[FLOAT, 512]
  %layer4.0.bn2.running_mean[FLOAT, 512]
  %layer4.0.bn2.running_var[FLOAT, 512]
  %layer4.0.bn2.weight[FLOAT, 512]
  %layer4.0.bn3.bias[FLOAT, 2048]
  %layer4.0.bn3.running_mean[FLOAT, 2048]
  %layer4.0.bn3.running_var[FLOAT, 2048]
  %layer4.0.bn3.weight[FLOAT, 2048]
  %layer4.0.conv1.weight[FLOAT, 512x1024x1x1]
  %layer4.0.conv2.weight[FLOAT, 512x512x3x3]
  %layer4.0.conv3.weight[FLOAT, 2048x512x1x1]
  %layer4.0.downsample.0.weight[FLOAT, 2048x1024x1x1]
  %layer4.0.downsample.1.bias[FLOAT, 2048]
  %layer4.0.downsample.1.running_mean[FLOAT, 2048]
  %layer4.0.downsample.1.running_var[FLOAT, 2048]
  %layer4.0.downsample.1.weight[FLOAT, 2048]
  %layer4.1.bn1.bias[FLOAT, 512]
  %layer4.1.bn1.running_mean[FLOAT, 512]
  %layer4.1.bn1.running_var[FLOAT, 512]
  %layer4.1.bn1.weight[FLOAT, 512]
  %layer4.1.bn2.bias[FLOAT, 512]
  %layer4.1.bn2.running_mean[FLOAT, 512]
  %layer4.1.bn2.running_var[FLOAT, 512]
  %layer4.1.bn2.weight[FLOAT, 512]
  %layer4.1.bn3.bias[FLOAT, 2048]
  %layer4.1.bn3.running_mean[FLOAT, 2048]
  %layer4.1.bn3.running_var[FLOAT, 2048]
  %layer4.1.bn3.weight[FLOAT, 2048]
  %layer4.1.conv1.weight[FLOAT, 512x2048x1x1]
  %layer4.1.conv2.weight[FLOAT, 512x512x3x3]
  %layer4.1.conv3.weight[FLOAT, 2048x512x1x1]
  %layer4.2.bn1.bias[FLOAT, 512]
  %layer4.2.bn1.running_mean[FLOAT, 512]
  %layer4.2.bn1.running_var[FLOAT, 512]
  %layer4.2.bn1.weight[FLOAT, 512]
  %layer4.2.bn2.bias[FLOAT, 512]
  %layer4.2.bn2.running_mean[FLOAT, 512]
  %layer4.2.bn2.running_var[FLOAT, 512]
  %layer4.2.bn2.weight[FLOAT, 512]
  %layer4.2.bn3.bias[FLOAT, 2048]
  %layer4.2.bn3.running_mean[FLOAT, 2048]
  %layer4.2.bn3.running_var[FLOAT, 2048]
  %layer4.2.bn3.weight[FLOAT, 2048]
  %layer4.2.conv1.weight[FLOAT, 512x2048x1x1]
  %layer4.2.conv2.weight[FLOAT, 512x512x3x3]
  %layer4.2.conv3.weight[FLOAT, 2048x512x1x1]
) {
  %321 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [2, 2]](%input, %conv1.weight)
  %322 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%321, %bn1.weight, %bn1.bias, %bn1.running_mean, %bn1.running_var)
  %323 = Relu(%322)
  %324 = MaxPool[ceil_mode = 0, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%323)
  %325 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%324, %layer1.0.conv1.weight)
  %326 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%325, %layer1.0.bn1.weight, %layer1.0.bn1.bias, %layer1.0.bn1.running_mean, %layer1.0.bn1.running_var)
  %327 = Relu(%326)
  %328 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%327, %layer1.0.conv2.weight)
  %329 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%328, %layer1.0.bn2.weight, %layer1.0.bn2.bias, %layer1.0.bn2.running_mean, %layer1.0.bn2.running_var)
  %330 = Relu(%329)
  %331 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%330, %layer1.0.conv3.weight)
  %332 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%331, %layer1.0.bn3.weight, %layer1.0.bn3.bias, %layer1.0.bn3.running_mean, %layer1.0.bn3.running_var)
  %333 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%324, %layer1.0.downsample.0.weight)
  %334 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%333, %layer1.0.downsample.1.weight, %layer1.0.downsample.1.bias, %layer1.0.downsample.1.running_mean, %layer1.0.downsample.1.running_var)
  %335 = Add(%332, %334)
  %336 = Relu(%335)
  %337 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%336, %layer1.1.conv1.weight)
  %338 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%337, %layer1.1.bn1.weight, %layer1.1.bn1.bias, %layer1.1.bn1.running_mean, %layer1.1.bn1.running_var)
  %339 = Relu(%338)
  %340 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%339, %layer1.1.conv2.weight)
  %341 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%340, %layer1.1.bn2.weight, %layer1.1.bn2.bias, %layer1.1.bn2.running_mean, %layer1.1.bn2.running_var)
  %342 = Relu(%341)
  %343 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%342, %layer1.1.conv3.weight)
  %344 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%343, %layer1.1.bn3.weight, %layer1.1.bn3.bias, %layer1.1.bn3.running_mean, %layer1.1.bn3.running_var)
  %345 = Add(%344, %336)
  %346 = Relu(%345)
  %347 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%346, %layer1.2.conv1.weight)
  %348 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%347, %layer1.2.bn1.weight, %layer1.2.bn1.bias, %layer1.2.bn1.running_mean, %layer1.2.bn1.running_var)
  %349 = Relu(%348)
  %350 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%349, %layer1.2.conv2.weight)
  %351 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%350, %layer1.2.bn2.weight, %layer1.2.bn2.bias, %layer1.2.bn2.running_mean, %layer1.2.bn2.running_var)
  %352 = Relu(%351)
  %353 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%352, %layer1.2.conv3.weight)
  %354 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%353, %layer1.2.bn3.weight, %layer1.2.bn3.bias, %layer1.2.bn3.running_mean, %layer1.2.bn3.running_var)
  %355 = Add(%354, %346)
  %356 = Relu(%355)
  %357 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%356, %layer2.0.conv1.weight)
  %358 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%357, %layer2.0.bn1.weight, %layer2.0.bn1.bias, %layer2.0.bn1.running_mean, %layer2.0.bn1.running_var)
  %359 = Relu(%358)
  %360 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%359, %layer2.0.conv2.weight)
  %361 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%360, %layer2.0.bn2.weight, %layer2.0.bn2.bias, %layer2.0.bn2.running_mean, %layer2.0.bn2.running_var)
  %362 = Relu(%361)
  %363 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%362, %layer2.0.conv3.weight)
  %364 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%363, %layer2.0.bn3.weight, %layer2.0.bn3.bias, %layer2.0.bn3.running_mean, %layer2.0.bn3.running_var)
  %365 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%356, %layer2.0.downsample.0.weight)
  %366 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%365, %layer2.0.downsample.1.weight, %layer2.0.downsample.1.bias, %layer2.0.downsample.1.running_mean, %layer2.0.downsample.1.running_var)
  %367 = Add(%364, %366)
  %368 = Relu(%367)
  %369 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%368, %layer2.1.conv1.weight)
  %370 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%369, %layer2.1.bn1.weight, %layer2.1.bn1.bias, %layer2.1.bn1.running_mean, %layer2.1.bn1.running_var)
  %371 = Relu(%370)
  %372 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%371, %layer2.1.conv2.weight)
  %373 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%372, %layer2.1.bn2.weight, %layer2.1.bn2.bias, %layer2.1.bn2.running_mean, %layer2.1.bn2.running_var)
  %374 = Relu(%373)
  %375 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%374, %layer2.1.conv3.weight)
  %376 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%375, %layer2.1.bn3.weight, %layer2.1.bn3.bias, %layer2.1.bn3.running_mean, %layer2.1.bn3.running_var)
  %377 = Add(%376, %368)
  %378 = Relu(%377)
  %379 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%378, %layer2.2.conv1.weight)
  %380 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%379, %layer2.2.bn1.weight, %layer2.2.bn1.bias, %layer2.2.bn1.running_mean, %layer2.2.bn1.running_var)
  %381 = Relu(%380)
  %382 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%381, %layer2.2.conv2.weight)
  %383 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%382, %layer2.2.bn2.weight, %layer2.2.bn2.bias, %layer2.2.bn2.running_mean, %layer2.2.bn2.running_var)
  %384 = Relu(%383)
  %385 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%384, %layer2.2.conv3.weight)
  %386 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%385, %layer2.2.bn3.weight, %layer2.2.bn3.bias, %layer2.2.bn3.running_mean, %layer2.2.bn3.running_var)
  %387 = Add(%386, %378)
  %388 = Relu(%387)
  %389 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%388, %layer2.3.conv1.weight)
  %390 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%389, %layer2.3.bn1.weight, %layer2.3.bn1.bias, %layer2.3.bn1.running_mean, %layer2.3.bn1.running_var)
  %391 = Relu(%390)
  %392 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%391, %layer2.3.conv2.weight)
  %393 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%392, %layer2.3.bn2.weight, %layer2.3.bn2.bias, %layer2.3.bn2.running_mean, %layer2.3.bn2.running_var)
  %394 = Relu(%393)
  %395 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%394, %layer2.3.conv3.weight)
  %396 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%395, %layer2.3.bn3.weight, %layer2.3.bn3.bias, %layer2.3.bn3.running_mean, %layer2.3.bn3.running_var)
  %397 = Add(%396, %388)
  %398 = Relu(%397)
  %399 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%398, %layer3.0.conv1.weight)
  %400 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%399, %layer3.0.bn1.weight, %layer3.0.bn1.bias, %layer3.0.bn1.running_mean, %layer3.0.bn1.running_var)
  %401 = Relu(%400)
  %402 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%401, %layer3.0.conv2.weight)
  %403 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%402, %layer3.0.bn2.weight, %layer3.0.bn2.bias, %layer3.0.bn2.running_mean, %layer3.0.bn2.running_var)
  %404 = Relu(%403)
  %405 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%404, %layer3.0.conv3.weight)
  %406 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%405, %layer3.0.bn3.weight, %layer3.0.bn3.bias, %layer3.0.bn3.running_mean, %layer3.0.bn3.running_var)
  %407 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%398, %layer3.0.downsample.0.weight)
  %408 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%407, %layer3.0.downsample.1.weight, %layer3.0.downsample.1.bias, %layer3.0.downsample.1.running_mean, %layer3.0.downsample.1.running_var)
  %409 = Add(%406, %408)
  %410 = Relu(%409)
  %411 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%410, %layer3.1.conv1.weight)
  %412 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%411, %layer3.1.bn1.weight, %layer3.1.bn1.bias, %layer3.1.bn1.running_mean, %layer3.1.bn1.running_var)
  %413 = Relu(%412)
  %414 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%413, %layer3.1.conv2.weight)
  %415 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%414, %layer3.1.bn2.weight, %layer3.1.bn2.bias, %layer3.1.bn2.running_mean, %layer3.1.bn2.running_var)
  %416 = Relu(%415)
  %417 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%416, %layer3.1.conv3.weight)
  %418 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%417, %layer3.1.bn3.weight, %layer3.1.bn3.bias, %layer3.1.bn3.running_mean, %layer3.1.bn3.running_var)
  %419 = Add(%418, %410)
  %420 = Relu(%419)
  %421 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%420, %layer3.2.conv1.weight)
  %422 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%421, %layer3.2.bn1.weight, %layer3.2.bn1.bias, %layer3.2.bn1.running_mean, %layer3.2.bn1.running_var)
  %423 = Relu(%422)
  %424 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%423, %layer3.2.conv2.weight)
  %425 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%424, %layer3.2.bn2.weight, %layer3.2.bn2.bias, %layer3.2.bn2.running_mean, %layer3.2.bn2.running_var)
  %426 = Relu(%425)
  %427 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%426, %layer3.2.conv3.weight)
  %428 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%427, %layer3.2.bn3.weight, %layer3.2.bn3.bias, %layer3.2.bn3.running_mean, %layer3.2.bn3.running_var)
  %429 = Add(%428, %420)
  %430 = Relu(%429)
  %431 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%430, %layer3.3.conv1.weight)
  %432 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%431, %layer3.3.bn1.weight, %layer3.3.bn1.bias, %layer3.3.bn1.running_mean, %layer3.3.bn1.running_var)
  %433 = Relu(%432)
  %434 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%433, %layer3.3.conv2.weight)
  %435 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%434, %layer3.3.bn2.weight, %layer3.3.bn2.bias, %layer3.3.bn2.running_mean, %layer3.3.bn2.running_var)
  %436 = Relu(%435)
  %437 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%436, %layer3.3.conv3.weight)
  %438 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%437, %layer3.3.bn3.weight, %layer3.3.bn3.bias, %layer3.3.bn3.running_mean, %layer3.3.bn3.running_var)
  %439 = Add(%438, %430)
  %440 = Relu(%439)
  %441 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%440, %layer3.4.conv1.weight)
  %442 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%441, %layer3.4.bn1.weight, %layer3.4.bn1.bias, %layer3.4.bn1.running_mean, %layer3.4.bn1.running_var)
  %443 = Relu(%442)
  %444 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%443, %layer3.4.conv2.weight)
  %445 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%444, %layer3.4.bn2.weight, %layer3.4.bn2.bias, %layer3.4.bn2.running_mean, %layer3.4.bn2.running_var)
  %446 = Relu(%445)
  %447 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%446, %layer3.4.conv3.weight)
  %448 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%447, %layer3.4.bn3.weight, %layer3.4.bn3.bias, %layer3.4.bn3.running_mean, %layer3.4.bn3.running_var)
  %449 = Add(%448, %440)
  %450 = Relu(%449)
  %451 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%450, %layer3.5.conv1.weight)
  %452 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%451, %layer3.5.bn1.weight, %layer3.5.bn1.bias, %layer3.5.bn1.running_mean, %layer3.5.bn1.running_var)
  %453 = Relu(%452)
  %454 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%453, %layer3.5.conv2.weight)
  %455 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%454, %layer3.5.bn2.weight, %layer3.5.bn2.bias, %layer3.5.bn2.running_mean, %layer3.5.bn2.running_var)
  %456 = Relu(%455)
  %457 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%456, %layer3.5.conv3.weight)
  %458 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%457, %layer3.5.bn3.weight, %layer3.5.bn3.bias, %layer3.5.bn3.running_mean, %layer3.5.bn3.running_var)
  %459 = Add(%458, %450)
  %460 = Relu(%459)
  %461 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%460, %layer4.0.conv1.weight)
  %462 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%461, %layer4.0.bn1.weight, %layer4.0.bn1.bias, %layer4.0.bn1.running_mean, %layer4.0.bn1.running_var)
  %463 = Relu(%462)
  %464 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%463, %layer4.0.conv2.weight)
  %465 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%464, %layer4.0.bn2.weight, %layer4.0.bn2.bias, %layer4.0.bn2.running_mean, %layer4.0.bn2.running_var)
  %466 = Relu(%465)
  %467 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%466, %layer4.0.conv3.weight)
  %468 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%467, %layer4.0.bn3.weight, %layer4.0.bn3.bias, %layer4.0.bn3.running_mean, %layer4.0.bn3.running_var)
  %469 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%460, %layer4.0.downsample.0.weight)
  %470 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%469, %layer4.0.downsample.1.weight, %layer4.0.downsample.1.bias, %layer4.0.downsample.1.running_mean, %layer4.0.downsample.1.running_var)
  %471 = Add(%468, %470)
  %472 = Relu(%471)
  %473 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%472, %layer4.1.conv1.weight)
  %474 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%473, %layer4.1.bn1.weight, %layer4.1.bn1.bias, %layer4.1.bn1.running_mean, %layer4.1.bn1.running_var)
  %475 = Relu(%474)
  %476 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%475, %layer4.1.conv2.weight)
  %477 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%476, %layer4.1.bn2.weight, %layer4.1.bn2.bias, %layer4.1.bn2.running_mean, %layer4.1.bn2.running_var)
  %478 = Relu(%477)
  %479 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%478, %layer4.1.conv3.weight)
  %480 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%479, %layer4.1.bn3.weight, %layer4.1.bn3.bias, %layer4.1.bn3.running_mean, %layer4.1.bn3.running_var)
  %481 = Add(%480, %472)
  %482 = Relu(%481)
  %483 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%482, %layer4.2.conv1.weight)
  %484 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%483, %layer4.2.bn1.weight, %layer4.2.bn1.bias, %layer4.2.bn1.running_mean, %layer4.2.bn1.running_var)
  %485 = Relu(%484)
  %486 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%485, %layer4.2.conv2.weight)
  %487 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%486, %layer4.2.bn2.weight, %layer4.2.bn2.bias, %layer4.2.bn2.running_mean, %layer4.2.bn2.running_var)
  %488 = Relu(%487)
  %489 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%488, %layer4.2.conv3.weight)
  %490 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%489, %layer4.2.bn3.weight, %layer4.2.bn3.bias, %layer4.2.bn3.running_mean, %layer4.2.bn3.running_var)
  %491 = Add(%490, %482)
  %492 = Relu(%491)
  %493 = GlobalAveragePool(%492)
  %494 = Flatten[axis = 1](%493)
  %output = Gemm[alpha = 1, beta = 1, transB = 1](%494, %fc.weight, %fc.bias)
  return %output
}
